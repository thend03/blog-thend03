---
draft: false
date: 2024-07-21T13:08:59+08:00
title: "如何做一个小报童分销导航"
slug: "how-to-make-a-xiaobot-nav" 
tags: ["xiaobot","spider","nav"]
categories: []
authors: ["since"]
description: "从0到1做1个小报童分销导航"
disableShare: true # 底部不显示分享栏
---

# 0x0

导航站的详细实操，讲了专栏来源的选择，如何整理获取专栏列表，前端样式怎么做，如何部署，生成最终的导航站。

由于前端能力实在有限，所以本篇文章的重点是在如何获取精选的专栏列表上。



# 小报童简介

[小报童](https://xiaobot.net/home.html)是个去中心化的课程平台。

> 创作者可以在小报童体面而用心的创作，专注创作，不搞套路。
>
> 而且专栏的价格大部分都比较便宜。
>
> 小报童官方不做社群，不做广告变现，不做算法推荐。



因为小报童是去中心化的，所以官网没有所有的专栏列表，只能通过专栏作者自发性的传播，或者小报童官方的推荐才能找到专栏地址。



所以有人就做了小报童的导航站，用来推荐专栏。



而且小报童这个不需要买专栏，就可以获得分销链接。所以理论上小报童的所有专栏都可以免费获得分销链接。

![image-20240721133751669](https://cdn.jsdelivr.net/gh/thend03/mdPic/picGo/202407211337712.png)

![image-20240721133805735](https://cdn.jsdelivr.net/gh/thend03/mdPic/picGo/202407211338766.png)



另外大声的吐槽一下，这样的专栏都是谁在买。





别人通过你的链接买了之后，你就可以获得分销收入。



但是吧，分销站这个东西，可能确实得有点私域流量才行，在pyq发分销的二维码，或者公众号发文章，或者自己的社群里发一下进行推荐。



单纯靠seo的话，目前排名比较靠前的seo做的都挺好的，新站感觉得做持久化运营搜索引擎排名才能上的去。



单搜小报童，官网占了整整一屏，下面的就是一些分销站了。	

![image-20240721133054830](https://cdn.jsdelivr.net/gh/thend03/mdPic/picGo/202407211330954.png)





回到分销站，该如何从01到1做一个分销站出来。



我努力搜索，都没有搜索出一个可用的分销导航模板出来，有点点难。



# 数据源

做导航站首先要拿到数据，由于小报童的特殊性(去中心化)，所以没法从官网得到所有专栏的数据。

那么可以选择从以下的几种渠道拿到数据

- 小报童精选公众号，里面会有一些精选专栏的推荐。
- pyq各种散落的专栏推荐
- 别人整理好的专栏列表
- 爬当前已有的小报童导航站的数据



## 小报童精选

小报童精选是小报童官方的公众号。

虽然是去中心化，但是一点入口都看不到，专栏的推广确实是会受阻。

所以有了小报童精选这个事。



精选文章每期会推荐一些有价值的专栏。所以精选是个获取专栏列表的路子。但是精选只能拿到一部分的专栏。



## pyq

pyq加的一些人，会去推荐专栏，他们买了之后，会发他们自己的专属分销海报。



有时候我也会去通过他们的链接买一点，但是这种就是随缘，数量也不会太多。



## 别人整理好的专栏列表

我在网上冲浪的时候，发现了别人有一份整理好的专栏列表，但是这个可能会有时效性的问题，作者更新不及时，就拿不到增量的专栏列表。

下面这个就是一个民间的版本，上次更新还是在2年前。

https://github.com/qianguyihao/xiaobot-list?tab=readme-ov-file



## 爬当前已有的导航站的数据

这条路我感觉是最好的，多选几个导航站，把他们的专栏列表都爬一遍，然后去个重，就得到了最新最全的专栏列表了。





# 数据源的选择

上面介绍了几种数据来源，我这边选择的是爬小报童精选的推荐列表。其实更好的是去爬已有导航站的数据。



不过就精选专栏而言，官方的其实更好，毕竟官方已经做过一轮筛选了，能上推荐的肯定有其优点。



# 数据整理分类

选择好之后，我们就需要对推荐列表进行分类，订阅号里有目前所有的专栏推荐列表。截止到现在一共有26期。

那么对推荐列表进行整理就有2种方法。

- 人工整理
- 爬虫分类



26期的话，点开26条公众号文章，收集下所有的推荐专栏的二维码，倒也还好。

但是作为一个资深crud boy，能写代码就写代码。不能写代码，就让chatgpt帮我们写代码。



语言选择的是Java(资深java crud仔)。



选择的框架有如下几个

- Jsoup, 用于解析html
- Fastjson2，用于字符串转json处理
- Hutool，http&二维码识别
- selenium,  用于浏览器模拟，一些异步加载的页面需要用到这个
- commons-io，文件操作

 下面就是实操了



## 如何拿到专栏推荐列表

首先是进入小报童精选 公众号的聊天页面，左下角有个往期回顾，这里就是推荐专栏的合集页面。

![image-20240721144801453](https://cdn.jsdelivr.net/gh/thend03/mdPic/picGo/202407211448481.png)





然后点击右上角，选择复制链接，或者选择使用默认浏览器打开，就可以拿到订阅列表的url

![image-20240721144817021](https://cdn.jsdelivr.net/gh/thend03/mdPic/picGo/202407211448061.png)





下面就是页面分析了，通过滑动页面猜测这个列表是分页加载的。



可以在控制台看网络请求，也可以看的出来。

 uri中有一个关键的key，appmsgalbum， 这个看着像是列表的请求。经过测验，这个确实是分页参数。

浏览器地址栏的链接访问只能访问到第一页的页面。下面就要靠分页查询拿数据了。



下面的分页请求返回的是json数据，第一页是html数据。



分页参数有2个比较关键的key，begin_msgid和begin_itemidx，这个一个是分页参数，一个是消息id，传入页数和id，查询下面的消息



![image-20240721150209139](https://cdn.jsdelivr.net/gh/thend03/mdPic/picGo/202407211502190.png)

![image-20240721152306897](https://cdn.jsdelivr.net/gh/thend03/mdPic/picGo/202407211523946.png)



这样的话就可以拿到所有的推荐文章的详细链接了。每一篇文章有一个专题推荐，包含数个专栏的推荐

经过页面选择元素以及debug，得到了如下获取订阅列表每篇文章地址的方法

常量类如下

```java
public class Constants {
    public static final String XIAOBOT_WECHAT_SUBSCRIBE_LIST_URL = "https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&__biz=Mzg4MTc0MDcyOA==&scene=1&album_id=2262723582487429130&count=100&uin=&key=&devicetype=iMac+MacBookPro18%2C1+OSX+OSX+14.5+build(23F79)&version=13080811&lang=zh_CN&nettype=WIFI&ascene=0&fontScale=100";

    public static final String LOCAL_CHROME_DRIVER_PATH = "/Users/since/Downloads/chromedriver-mac-arm64/chromedriver";

    public static final String LIST_NEXT_URL_FORMAT = "https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&__biz=Mzg4MTc0MDcyOA==&album_id=2262723582487429130&count=100&begin_msgid=%s&begin_itemidx=%s&uin=&key=&pass_ticket=&wxtoken=&devicetype=iMac&nbsp;MacBookPro18,1&nbsp;OSX&nbsp;OSX&nbsp;14.5&nbsp;build(23F79)&clientversion=13080811&__biz=Mzg4MTc0MDcyOA==&appmsg_token=&x5=0&f=json";

}
```



获取订阅列表方法

```java
import cn.hutool.http.HttpUtil;
import com.alibaba.fastjson2.JSON;
import com.alibaba.fastjson2.JSONArray;
import com.alibaba.fastjson2.JSONObject;
import com.thend03.xiaobot.spider.constants.Constants;
import com.thend03.xiaobot.spider.model.ArticleDetail;
import com.thend03.xiaobot.spider.model.WechatModel;
import org.apache.commons.collections4.CollectionUtils;
import org.apache.commons.lang3.StringUtils;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Attributes;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;

import java.net.MalformedURLException;
import java.nio.charset.StandardCharsets;
import java.util.ArrayList;
import java.util.List;
import java.util.Objects;
import java.util.stream.Collectors;

/**
 * 小报童专栏精选订阅号列表解析服务
 *
 * @author since
 * @date 2024-07-17 08:12
 */
public class WechatSubscribeListService {

    public static List<ArticleDetail> parseArticleList() {

        String content = HttpUtil.downloadString(Constants.XIAOBOT_WECHAT_SUBSCRIBE_LIST_URL, StandardCharsets.UTF_8);

        Document parse = Jsoup.parse(content);
        Elements albumListItem = parse.getElementsByClass("album__list-item");
        System.out.println(1);
        List<WechatModel> list = new ArrayList<>();
        boolean hasNext = true;
        for (Element element : albumListItem) {
            Attributes attributes = element.attributes();
            System.out.println(2);
            if (attributes.isEmpty()) {
                continue;
            }
            String s = attributes.get("data-msgid");
            String s1 = attributes.get("data-itemidx");
            String s2 = attributes.get("data-link");
            String s3 = attributes.get("data-title");
            String s4 = attributes.get("data-pos_num");

            WechatModel wechatModel = new WechatModel();
            wechatModel.setDataMsgId(parseLong(s));
            wechatModel.setDataItemIndex(parseInt(s1));
            wechatModel.setDataLink(s2);
            wechatModel.setDataTitle(s3);
            wechatModel.setDataPosNum(parseInt(s4));
            list.add(wechatModel);
            if (wechatModel.getDataPosNum() == 1) {
                hasNext = false;
            }
        }
        while (hasNext) {
            List<WechatModel> list1 = nextParse(list.get(list.size() - 1));
            if (CollectionUtils.isNotEmpty(list1)) {
                list.addAll(list1);

            }
            if (list1.get(list1.size() - 1).getDataPosNum() == 1) {
                hasNext = false;
            }
        }

        List<String> urlList = new ArrayList<>();
        list.stream().filter(Objects::nonNull).forEach(s -> {
            List<String> urlList1 = WechatDetailService.getUrlList(s.getDataLink());
            if (CollectionUtils.isNotEmpty(urlList1)) {
                urlList.addAll(urlList1);
            }
        });

        List<String> collect = urlList.stream().filter(StringUtils::isNotBlank).filter(s -> s.contains("http") && s.contains("xiaobot.net/p")).map(s -> {
            String[] split = s.split("\\?");
            return split[0];
        }).distinct().collect(Collectors.toList());
        List<ArticleDetail> collect1 = collect.stream().filter(Objects::nonNull).map(url -> {
            String host = null;
            String uniqueId = null;
            try {
                host = WechatDetailService.getHost(url);
            } catch (MalformedURLException e) {


            }
            try {
                uniqueId = WechatDetailService.getArticleUniqueId(url);
            } catch (MalformedURLException e) {
                throw new RuntimeException(e);
            }
            return WechatDetailService.getArticleDetail(host, uniqueId);
        }).collect(Collectors.toList());
        return collect1;
    }

    public static long parseLong(String dataMsgId) {
        try {
            return Long.parseLong(dataMsgId);
        } catch (Exception e) {
            e.printStackTrace();
        }
        return -1;
    }

    public static int parseInt(String itemIndex) {
        try {
            return Integer.parseInt(itemIndex);
        } catch (Exception e) {
            e.printStackTrace();
        }
        return -1;
    }

    public static List<WechatModel> nextParse(WechatModel wechatModel) {
        List<WechatModel> list = new ArrayList<>();
        String format = String.format(Constants.LIST_NEXT_URL_FORMAT, wechatModel.getDataMsgId(), wechatModel.getDataItemIndex());
        String content = HttpUtil.downloadString(format, StandardCharsets.UTF_8);
        JSONObject jsonObject = JSON.parseObject(content);
        JSONObject getalbumResp = jsonObject.getJSONObject("getalbum_resp");
        JSONArray articleList = getalbumResp.getJSONArray("article_list");
        for (int i = 0; i < articleList.size(); i++) {
            Object o = articleList.get(i);
            if (o instanceof JSONObject) {
                JSONObject json = (JSONObject) o;
                long msgid = json.getLongValue("msgid");
                int itemidx = json.getIntValue("itemidx");
                int posNum = json.getIntValue("pos_num");
                String title = json.getString("title");
                String link = json.getString("url");
                WechatModel nextWechatModel = new WechatModel();
                nextWechatModel.setDataMsgId(msgid);
                nextWechatModel.setDataItemIndex(itemidx);
                nextWechatModel.setDataLink(link);
                nextWechatModel.setDataTitle(title);
                nextWechatModel.setDataPosNum(posNum);
                list.add(nextWechatModel);
            }
        }
        return list;
    }
}

```

## 

